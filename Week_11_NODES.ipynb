{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of Nerual ODEs or How I Learned the Velocity of a Falling Object\n",
    "\n",
    "If you recall from your intro physcis class, the velocity of a falling ball at some time with quadratic drag is given by, \n",
    "\n",
    "$$ \\frac{dv}{dt} = \\theta_1 + \\theta_2 v^{2} $$\n",
    "\n",
    "This is simply newtons law stating that the change velocity with respect to time is given by the the the graviational constant (which works to speed up the ball) minus some constant times the square fo the velocity (which works to reduce the speed of the ball). \n",
    "\n",
    "Lets say we have some noisy observations, and we want to find the parameters of this ODE that describes the velocity.\n",
    "\n",
    "Before starting the exercise, you will want to install the `torchdiffeq` package with `pip install torchdiffeq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import odeint #This will solve our ODEs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "\n",
    "def dvdt(v, t, thetas): # velocity of the falling baseball from newton\n",
    "    ### TODO implement the dynamics function provided above given a list of thetas\n",
    "    ### Hint: The t argument is just present to make the ode solver happy. It is not actually used in the function.\n",
    "    return ???\n",
    "\n",
    "times = np.linspace(0, 3, 50) #We have 50 observations from our inital state \n",
    "true_thetas = [10, -.2] #The dynamics parameters for our generated data\n",
    "initial_velocity = 0 #The initial condition of our velocity\n",
    "\n",
    "out = odeint(dvdt, initial_velocity, times, (true_thetas,)) #Integrate our dynamics function outputting at each time\n",
    "vel_train = out[:,0]\n",
    "\n",
    "# Add some noise to give us our true 'observations'\n",
    "vel_train = vel_train + np.random.randn(vel_train.size)/10.\n",
    "\n",
    "# Now, let's pretend like we don't know the true values of our thetas.\n",
    "guess_thetas = [4., -1.] #let's make an inital guess as to what the dynmaics parameters might be.\n",
    "\n",
    "### This is for plotting later\n",
    "meshv = np.linspace(0, 9, 27)\n",
    "mesht = np.linspace(0, 3, 12)\n",
    "meshv, mesht = np.meshgrid(meshv,mesht)\n",
    "changet = np.ones(meshv.shape)*5\n",
    "\n",
    "\n",
    "### TODO implement the ode solver for your initial guess (guess_thetas)\n",
    "### arguments of odeint are a function, the initial state, the output times, and extra function args (will be similar to before)\n",
    "### If you're unsure about this, try playing around with the times and initial velocity to see what happens\n",
    "out = ???\n",
    "vel_guess = out[:,0]\n",
    "\n",
    "plt.figure(figsize =(10,7))\n",
    "plt.plot(times, vel_train, '.', label = 'Data') #plot the data and the inital guess\n",
    "plt.plot(times, vel_guess, label = 'Initial Guess')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Velocity (m/s)')\n",
    "plt.title('Ball Velocity Data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to train our parameters. The adjoint state derivatives gives the loss gradient at any point in the network. This problem has no explicit dependance on t which simplifies it a bit. \n",
    "\n",
    "$$ \\frac{da_{\\theta}(t)}{dt} = -a_{v}(t)\\frac{\\partial f(v(t),\\theta)}{\\partial \\theta} $$\n",
    "\n",
    "$$ a_{\\theta}(t) = \\frac{dL}{d\\theta} $$\n",
    "\n",
    "We have two parameters so we need to solve two odes. $ \\frac{\\partial f(v(t),\\theta)}{\\partial \\theta} $ can be derived from our equation for $f = \\frac{dv}{dt}$ above.\n",
    "\n",
    "$$ \\frac{da_{\\theta 1}(t)}{dt} = -a_{v}(t) $$\n",
    "\n",
    "$$ \\frac{da_{\\theta 2}(t)}{dt} = -a_{v}(t)*v(t)^2 $$\n",
    "\n",
    "But in order to solve this equation we also need \n",
    "\n",
    "$$ \\frac{da_{v}(t)}{dt} = -a_{v}(t)\\frac{\\partial f(v(t),t,\\theta)}{\\partial v(t)} $$\n",
    "\n",
    "But since our data is fairly closely spaced, we can assume the the adjoint velocity gradient is constant at each observation.\n",
    "\n",
    "$$ a_{v}(t) = \\frac{dL}{dv(t)} = 2*(v -v_{obs})$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fallingvelocity():\n",
    "    \n",
    "    def __init__(self, observations, thetas, times):\n",
    "        \n",
    "        self.observations = observations #our observation velocity\n",
    "        self.thetas = thetas  #list of initial params must have opposite signs!\n",
    "        self.times = times #our observation times\n",
    "        \n",
    "        \n",
    "    def _dvdt(self, v, t): ### velocity of the falling baseball from newton\n",
    "        ###Hint: v and t are just  arguments to make odeint happy. They are not used in either of the\n",
    "        ### adjoint functions\n",
    "        return ???\n",
    "\n",
    "    def _adjointodetheta1(self, v, t, Lossgrad): #adjoint ODE for the first parameter\n",
    "        ###TODO implement the adjoint ODE for theta 1\n",
    "        ###Hint: v and t are just  arguments to make odeint happy. They are not used in either of the\n",
    "        ### adjoint functions\n",
    "        return ???            \n",
    "    \n",
    "    def _adjointodetheta2(self, v, t, Lossgrad, v_current): #adjoint ODE for the second parameter\n",
    "        ###TODO implement the adjoint ODE for theta 2\n",
    "        return ???\n",
    "\n",
    "    \n",
    "    def adjoint(self, output):\n",
    "        \n",
    "        currentvel = output #initial velocity \n",
    "        \n",
    "        timeback = self.times[::-1] #since we are integrating backwards through the network\n",
    "        \n",
    "        gradsum1 = 0. #This will contain the cumulative loss with respect to parameter 1\n",
    "        \n",
    "        gradsum2 = 0. #This will contain the cumulative loss with respect to parameter 2\n",
    "    \n",
    "        for i in range(len(self.times)-1): #Solve odes between each datapoint\n",
    "            \n",
    "            initial1 = 0.0 #initial condition for the adjoint weights\n",
    "            initial2 = 0.0 #initial condition for the adjoint weights\n",
    "            \n",
    "            observed_velocity = self.observations[-(i+1)]\n",
    "            # TODO: Calculate loss with respect to current state.\n",
    "            Lossgrad = ??? #Loss gradient to ODEs at initalize at given observation\n",
    "            \n",
    "            ## Here is where we integrate backwards through the network\n",
    "            \n",
    "            backward_time_range = timeback[i:(i+2)]\n",
    "            ###TODO add ajoint for theta1 \n",
    "            backward = odeint(???)\n",
    "            gradsum1 += backward[-1] #add this to your loss gradient wrt parameter 1 to get cumulative gradient\n",
    "\n",
    "            ## TODO Same for parameter 2\n",
    "            backward2 = odeint(???)\n",
    "            gradsum2 += backward2[-1] #add this to your loss gradient wrt parameter 2 to get cumulative gradient\n",
    "            \n",
    "            #TODO Integrate velocity backward to to get value at next time step\n",
    "            currentvel = odeint(???)[-1]\n",
    "              \n",
    "            \n",
    "        return gradsum1, gradsum2 #??? What am I returning here?\n",
    "    \n",
    "    def forward(self):\n",
    "        \n",
    "        #Forward pass integration to get final velocity\n",
    "        out = odeint(self._dvdt, 0, self.times)\n",
    "        \n",
    "        out = out[:,0]\n",
    "        \n",
    "        return out #all velocities are stored merely for ease of plotting purposes. \n",
    "    \n",
    "model = fallingvelocity(vel_train, [4., -1.], times)\n",
    "\n",
    "eps = 0.0005 # Step size to take. Breaks pretty easily, be careful here\n",
    "\n",
    "for i in range(6500):\n",
    "\n",
    "    output = model.forward()\n",
    "    \n",
    "    gradt1, gradt2 = model.adjoint(output[-1]) ### Only feed the model the final state for backward pass\n",
    "    \n",
    "    ### TODO update thetas\n",
    "    model.thetas[0] -= ???\n",
    "    model.thetas[1] -= ???\n",
    "       \n",
    "    if i % 100 == 0:\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize = (15, 7))\n",
    "        plt.subplot(121)\n",
    "        plt.plot(times, vel_train, '.r', label='Observations')\n",
    "        plt.plot(times, output, 'b', label='Leared Dynamics', linewidth = 2)\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Velocity (m/s)')\n",
    "        plt.legend()\n",
    "        plt.subplot(122)\n",
    "        changev = dvdt(meshv, mesht, model.thetas)\n",
    "        plt.quiver(mesht, meshv, changet, changev, width = .005)\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Velocity (m/s)')\n",
    "        plt.title('Underlying Dynamics')\n",
    "        plt.show()\n",
    "        print('Iter {:04d}'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: $\\frac{dL}{d\\theta}$ was reset to zero at each observation point during the backward pass. Why was this?\n",
    "\n",
    "### Question 2: What would happen the velocity trajectory if we only had observations of the initial and final state?\n",
    "\n",
    "### Question 3: This model makes the assumption that $\\frac{dL}{dv}$ is constant between observations. Apparently it did not affect the model's ability to converge. When might this assumption cause problems?\n",
    "\n",
    "### Question 4: Run the model again, but alter the observation data times so they are no longer evenly spaced. Does this method still work?\n",
    "\n",
    "## Let's find the velocity again with a neural network\n",
    "\n",
    "In the previous example, we explicitly knew the ODE that described the dynamics of the velocity.\n",
    "\n",
    "$$ \\frac{dv}{dt} = \\theta_1 + \\theta_2 v^{2} $$\n",
    "\n",
    "If we don't know the ODE that describes the velocity, we can represent it with a neural network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchdiffeq import odeint as odeint_nn\n",
    "from torchdiffeq import odeint_adjoint ## Can use this if we want to use the adjoint method\n",
    "\n",
    "# NN that will be used to approximate dvdt \n",
    "class ODEFunc(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ODEFunc, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1, 50),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(50, 1),\n",
    "        )\n",
    "\n",
    "        for m in self.net.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.1)\n",
    "                nn.init.constant_(m.bias, val=0)\n",
    "\n",
    "    def forward(self, t, y):\n",
    "        return self.net(y)\n",
    "\n",
    "    \n",
    "# Number of time steps to integrate forward\n",
    "batch_time = 10\n",
    "# Number of batch samples to use in each gradient descent step\n",
    "batch_size = 10\n",
    "\n",
    "# This is how minibatch is imiplemented in the torchdiffeq examples. Interestingly, the model can get good \n",
    "# results by only training on 10 data points at a time.\n",
    "def get_batch(y, t):\n",
    "    \n",
    "    true_y = torch.Tensor(y)\n",
    "    t = torch.Tensor(t)\n",
    "    \n",
    "    s = torch.from_numpy(np.random.choice(np.arange(len(t) - batch_time, dtype=np.int64), batch_size, replace=False))\n",
    "    batch_y0 = true_y[s]  # (M, D)\n",
    "    batch_t = t[:batch_time]  # (T)\n",
    "    batch_y = torch.stack([true_y[s + i] for i in range(batch_time)], dim=0)  # (T, M, D)\n",
    "    return batch_y0, batch_t, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_train2 = vel_train[:,np.newaxis]\n",
    "\n",
    "model = ODEFunc()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=1e-3)\n",
    "\n",
    "for itr in range(1000):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Get initial state, time steps, true y values at each timestep.\n",
    "    batch_y0, batch_t, batch_y = get_batch(vel_train2, times)\n",
    "\n",
    "    # TODO: Use NODE to integrate forward\n",
    "    # Hint: The odeint implemented in the torchdiffeq package uses the same syntax as the scipy odeint function.\n",
    "    #       Only now, we are using a NN instead of a predefined dvdt function.\n",
    "    pred_y = odeint_nn(???)\n",
    "    # NOTE: We are just backpropagating throught the ODE solver here. However, if we want to use the \n",
    "    #       adjoint method implemented in torchdiffeq, all we have to do is call odeint_adjoint() rather\n",
    "    #       than odeint_nn(). Both functions use the same syntax.\n",
    "    \n",
    "    \n",
    "    # loss = torch.sqrt(torch.mean((pred_y - batch_y) ** 2))\n",
    "    loss = torch.mean(torch.abs(pred_y - batch_y))\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if itr % 100 == 0:\n",
    "        clear_output(wait=True)\n",
    "        with torch.no_grad():\n",
    "            plt.figure(figsize = (15, 7))\n",
    "            plt.subplot(121)\n",
    "            # TODO: Run model forward from time zero at all time steps so we can track progress\n",
    "            pred_y = odeint_nn(???)\n",
    "            loss = torch.mean(torch.abs(pred_y - torch.Tensor(vel_train2)))\n",
    "            plt.plot(times, vel_train2, '.r', label='Observations')\n",
    "            plt.plot(times, pred_y, 'b', label='NODE Model')\n",
    "            plt.xlabel('Time (s)')\n",
    "            plt.ylabel('Velocity (m/s)')\n",
    "            plt.legend()\n",
    "            plt.subplot(122)\n",
    "            \n",
    "            for i in range(4*3):\n",
    "                for j in range(9*3):\n",
    "                    changev = model.forward(i/3, torch.tensor([float(j/3)]))\n",
    "                    plt.quiver(i/3, j/3, 5, changev, width = .005, headwidth = 3)\n",
    "            plt.xlabel('Time (s)'),\n",
    "            plt.ylabel('Velocity (m/s)')\n",
    "            plt.title('Underlying Dynamics')\n",
    "            plt.show()\n",
    "            print('Iter {:04d} | Loss {:.6f}'.format(itr, loss.item()))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Question 5: Try swapping odeint_nn with odeint_adjoint and retraining the model. Is there a change in runtime or number of iterations before convergence? Why do you think we are seeing these differences between the two methods?\n",
    "\n",
    "### Question 6: Why might this example be a bad problem to solve with the adjoint method?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
